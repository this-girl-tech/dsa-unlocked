ğŸ§  Time & Space Complexity (The Smart Way to Understand Algorithms)
===================================================================

Complexity helps you understand how an algorithm behaves as input size grows.Once you master this, solving DSA problems becomes faster, easier, and far more predictable.

This guide covers the **most important complexity concepts** you must know â€” with clear rules, examples, and patterns.

â­ 1. Big-O Notation
===================

**What Big-O tells you**
------------------------

*   How **fast** your code runs
    
*   How **much memory** it uses
    
*   Whether your approach will **scale**
    

**Common Big-O Complexities**
-----------------------------


| Complexity           | Meaning                        | Examples                |
|----------------------|--------------------------------|-------------------------|
| O(1)                 | Constant                       |Array index, Hash lookup |
| O(log n)             | Shrinks input each step        | Binary search           |
| O(n)                 | Linear scan                    |  Single loop            |
| O(n log n)           | Efficient scaling              |   Merge sort            |
| O(nÂ²)                | Double loops                   |   Matrix problems       |
| O(2â¿)                | All subsets                    |   Backtracking          |
| O(n!)                | All permutations               |    Permutation problems |


â­ 2. How to Calculate Time Complexity
=====================================

**Rules**
---------

*   Ignore constants â†’ O(2n + 10) â†’ **O(n)**
    
*   Keep highest term â†’ O(nÂ² + n) â†’ **O(nÂ²)**
    
*   Loops define complexity
    

**Examples**
------------

### **Single Loop**

`   for (let i = 0; i < n; i++) {}  // O(n)   `

### **Nested Loops**

`   for (let i = 0; i < n; i++)    for (let j = 0; j < n; j++) {}  // O(nÂ²)   `

### **Shrinking Input**

`   while (n > 1) n /= 2;  // O(log n)   `

â­ 3. Understanding O(log n)
===========================

**When it appears**
-------------------

*   Binary search
    
*   Heaps
    
*   Balanced BSTs
    
*   Divide & Conquer algorithms
    

**Why itâ€™s extremely fast**
---------------------------

`   n â†’ n/2 â†’ n/4 â†’ n/8 â†’ ... â†’ 1    Total steps = logâ‚‚(n)   `

Even for 1,000,000, only ~20 steps.

â­ 4. Practical Complexity Examples
==================================

**Best Possible Complexities**

*   Search in sorted array â†’ **O(log n)**
    
*   Find max/min â†’ **O(n)**
    
*   Sorting â†’ **O(n log n)**
    
*   BFS/DFS â†’ **O(V + E)**
    
*   Sliding window â†’ **O(n)**
    
*   Subsets â†’ **O(2â¿)**
    
*   Permutations â†’ **O(n!)**
    

â­ 5. Space Complexity
=====================

**What it measures**
--------------------

How much **extra memory** your algorithm uses.

**Common Space Costs**
----------------------

| Space                | Operation                      |           
|----------------------|--------------------------------|
| O(1)                 | Swap variables                 |
| O(n)                 | Extra array or DP table        | 
| O(n)                 | HashMap / Set                  |  
| O(h)                 | Recursion depth                |   
| O(n)                 | Merge Sort                     |   


**Example**
-----------

`   function fact(n) {    if (n === 0) return 1;    return n * fact(n - 1);  }  // SC = O(n) because recursion uses stack memory   `

â­ 6. Timeâ€“Space Trade-Off
=========================

**Common Scenarios**
--------------------

*   Hashing â†’ faster lookups, uses more memory
    
*   Prefix sum â†’ O(1) queries, O(n) space
    
*   Memoization â†’ reduces time, increases space
    

â­ 7. Common Mistakes
====================

*   **O(n + n) = O(nÂ²)** â€” Incorrect. Correct â†’ **O(n)**
    
*   **Ignoring worst case** (e.g., QuickSort worst â†’ O(nÂ²))
    
*   **Forgetting recursion uses memory** â€” each call adds stack frame
    
*   **Counting operations instead of patterns** â€” analyze growth, not exact steps
    

â­ 8. Complexity Patterns (Quick Cheatsheet)
===========================================

**Loop Patterns**
-----------------

`   for(...)            â†’ O(n)  for inside for      â†’ O(nÂ²)  while(n /= 2)       â†’ O(log n)   `

**Recursion Patterns**
----------------------

`   Divide & Conquer    â†’ O(n log n)  Subsets             â†’ O(2â¿)  Permutations        â†’ O(n!)  Tree DFS            â†’ O(n)   `

**Hashing**
-----------

`   Insert   â†’ O(1)  Search   â†’ O(1)  Delete   â†’ O(1)   `


â­ 9. Quick Judge Guide
=======================

**If your input size is:**

*   n â‰¤ 10Â³ â†’ O(nÂ²) acceptable
    
*   n â‰¤ 10âµ â†’ O(n log n) required
    
*   n â‰¤ 10â¶ â†’ O(n) required
    
*   n â‰¥ 10â· â†’ O(log n) or O(1) only
    

â­ 10. Master Heuristics (Remember These)
========================================

*   Shrinking input â†’ **O(log n)**
    
*   Scan all elements â†’ **O(n)**
    
*   Sort + scan â†’ **O(n log n)**
    
*   Two nested loops â†’ **O(nÂ²)**
    
*   All subsets â†’ **O(2â¿)**
    
*   All permutations â†’ **O(n!)**
    

These shortcuts help you estimate complexity instantly.

ğŸŒ¸ Final Note
=============

Complexity isnâ€™t about mathematics â€”itâ€™s about recognizing **how your algorithm grows** as the input becomes bigger.

Once these patterns click, evaluating efficiency becomes effortless.

Keep practicing. Youâ€™re leveling up every day. ğŸš€
